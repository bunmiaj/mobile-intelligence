---
title: "MIB: Accessing and Querying Data Using `rmongodb`"
author: "[Truc Viet 'Joe' Le](mailto:tjle@andrew.cmu.edu)"
date: "`r Sys.Date()`"
output: html_document
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(ig.width=4, fig.height=3, fig.path='./mongo_fig/',
                      warning=FALSE)
```

This tutorial demonstrates how to connect to the MongoDB server that hosts the datasets used for the MIB coursework project. Before we begin, make sure that your computer is being connected to the CMU campus network. If you are off campus, you will need to access it via VPN, see <http://www.cmu.edu/computing/network/vpn/>. I assume that by now you have successfully installed `R` and `RStudio` in your computer. I also assume that you have installed the `R` package `rmongodb`. If you have not, do it by typing

```{r install_packages, eval=FALSE}
install.packages("rmongodb", dependencies=TRUE)
```

in the console of `RStudio`. Two other packages that we will be using frequently in this course are `plyr` (for data manipulation) and `ggplot2` (for data visualization), so make sure you have them installed as well.

We first load the installed packages:

```{r load_packages, include=TRUE}
library(rmongodb)
library(ggplot2)
library(scales) ## for plot formatting
library(plyr)
```

We then declare the following variables for the server name and login credentials, which allow you to retrieve the data from the server and make queries, but not writing to the server.

```{r login_credentials, results='hide'}
host <- "heinz-tjle.heinz.cmu.edu"
username <- "student"
password <- "helloWorld"
db <- "admin" ## our database is called `admin'
```

You are now ready to connect to the server. Do it by typing:

```{r make_connection}
mongo <- mongo.create(host = host, db = db, username = username, password = password)
```

Under normal circumstances, the connection will be successful and nothing will be printed out. Otherwise, an error message will appear. Our connection variable is called `mongo` and will be used throughout the session. To confirm that we have successfully connected to the server, use the following command, and the result will be printed out.

```{r confirm_connection}
mongo.is.connected(mongo)
```

We now declare variables for the collection name and namespace. If you are familiar with SQL, a **collection** in MongoDB is like a **BIG** SQL table that can contain millions of rows. A **namespace** is just a concatenation of the database name and the collection name with a period character in between.

```{r namespace}
collection <- "cellular" ## we are using the mobile phone data for now
namespace <- paste(db, collection, sep=".")
```

Note that we are using the `cellular` collection throughout this tutorial. The other two collections can be accessed similarly. We are now ready to make our first query. Before we do that, we wish to know what collections are there in the database?

```{r show_collections}
mongo.get.database.collections(mongo, db="admin")
```

The results above show that we have three collections: `cellular` (the **mobile phone** data), `taxi` (the **taxicab** data), and `income` (the **taxi fare** data). Suppose our current namespace is unchanged, we can query the number of records in the `cellular` collection as:

```{r num_records}
mongo.count(mongo, namespace)
```

It is often useful to have a rough picture of what our records look like in the collection (like what fields are there). Then, you'd want to see a sample record in the current collection:

```{r sample_record}
(sample <- mongo.find.one(mongo, namespace))
```

We know that each record contains an **IMEI number** (among many other things), which uniquely identifies a mobile phone device. Suppose now we know an IMEI number and we wish to retrieve all call records from that particular IMEI in our collection. We can define a query to do that. We also wish to define the fields that we are interested in (and not all of them) in our retrieved data since not all information is equally useful.

```{r retrieve_imei, results='hide'}
## Define the query
query <- mongo.bson.from.list(list('imei'=355001000488650))
## Define the fields to be returned
fields <- mongo.bson.buffer.create()
## '1L' means we want to turn this field on, '0L' to turn it off
mongo.bson.buffer.append(fields, "_id", 0L)
mongo.bson.buffer.append(fields, "caller_id", 1L)
mongo.bson.buffer.append(fields, "callee_id", 1L)
mongo.bson.buffer.append(fields, "date", 1L)
mongo.bson.buffer.append(fields, "time", 1L)
mongo.bson.buffer.append(fields, "call_duration", 1L)
mongo.bson.buffer.append(fields, "cell_id", 1L)
## Make an object from the buffer
fields <- mongo.bson.from.buffer(fields)
```

The result is a **cursor** object that represents a pointer to the results of our query. To get the actual records, we need to iterate over them, record by record. We also want to store the retrieved records in an `R` data frame called `call.data` for further analysis.

```{r query_imei}
## Create the query cursor
cursor <- mongo.find(mongo, namespace, query=query, fields=fields)
## Define a master data frame to store results
call.data <- data.frame(stringsAsFactors=FALSE)
## Iterate over the cursor
while(mongo.cursor.next(cursor)) {
  ## Iterate and grab the next record
  value <- mongo.cursor.value(cursor)
  call <- mongo.bson.to.list(value)
  ## Make it a data frame
  call.df <- as.data.frame(t(unlist(call)), stringsAsFactors=FALSE)
  ## Bind to the master data frame
  call.data <- rbind.fill(call.data, call.df)
}
## Release the resources attached to cursor on both client and server
done <- mongo.cursor.destroy(cursor)
## View the retrieved data frame
(call.data)
```

Suppose now we are interested in retrieving **all** phone calls on the date 03/01/2008. But then we realize that that would be **a lot** of data to handle, and it probably would take **a lot** of time and memory to retrieve and load. We thus use the option `limit` to limit the number of records retrieved.

```{r query_limit}
## Define the query
query <- mongo.bson.from.list(list('date'=20080301))
## Retrieve only the first 100 records
calls <- mongo.find.all(mongo, namespace, query=query, limit=100L)
```

Now we are curious about the **cell towers**. Remember that each cell tower is a spatial location with latitude and longitude coordinates. If we wish to retrieve the list of all cell tower ID's and count how many of them there are, then we make the following query:

```{r query_distinct}
## Get the list of distinct cell tower locations. WARNING: This may take a while
all.locs <- mongo.distinct(mongo, namespace, "cell_id")
## Convert from list to vector
loc.vector <- unlist(all.locs)
## Take a look at the first 15 cell_id's
head(loc.vector, 15)
## How many locations are there?
length(loc.vector)
```

The returned list, however, doesn't tell us about the **distribution** of those cell towers, i.e., how many calls were made near each of the towers. This distribution will tell us valuable information about the population density in the city during the time period, over the days of a week, or over the hours of a day. In order to retrieve such a distribution, we need a more advanced querying method. Fortunately, MongoDB comes with the powerful **aggregation framework** that streamlines the data retrieval process as a **pipeline** and allows applying useful **operators** along the way to reduce the complexity of data retrieval. Learn more about the aggregation framework here: <http://docs.mongodb.org/manual/core/aggregation-introduction/>.

The following lines will do the job of getting the distribution of all cell towers in the data. It is done by first grouping the cell towers by their `cell_id` and then counting the frequency of each `cell_id` by using the `$sum` operator. We then sort the cell towers by frequency in descending order (using the `$sort` operator). Notice that this pipeline is constructed using JSON format, which is then converted into BSON format and read by MongoDB. The retrieved list is finally converted into a data frame for analytical convenience.

```{r query_distribution}
## WARNING: This may take some time
## First, group by cell_id and count the frequencies
pipe_1 <- mongo.bson.from.JSON(
  '{"$group":
    {"_id": "$cell_id", "count": {"$sum": 1}}
  }'
)
## Then, sort by frequency in descending order
pipe_2 <- mongo.bson.from.JSON(
  '{"$sort": {"count": -1}}'
)
## Concatenate the pipeline
pipeline <- list(pipe_1, pipe_2)
## Run the aggregation pipeline
loc.distr <- mongo.aggregation(mongo, namespace, pipeline)

## Reshape the data to fit into an R data frame
lloc.distr <- mongo.bson.value(loc.distr, "result")
mloc.distr <- sapply(lloc.distr, function(x) return(c(toString(x["_id"]),
                                                      as.numeric(x["count"]))))
## Convert into R data frame
dloc.distr <- as.data.frame(t(mloc.distr))
colnames(dloc.distr) <- c("cell_id", "freq")
dloc.distr$freq <- as.numeric(dloc.distr$freq)
```

We are now ready to plot the distribution of the cell tower location frequencies.

```{r plot_histogram}
(ggplot(dloc.distr, aes(freq)) + geom_histogram(binwidth=50, fill="#c0392b", alpha=0.75) +
  labs(title="Distribution of Cell Tower Counts",
       x="Count", y="Frequency") + scale_x_continuous(labels=comma) +
  scale_y_continuous(labels=comma) + geom_hline(yintercept=0, size=0.4, color="black"))
```

Finally, we also wish to know the distribution of IMEI's -- which can be done similarly as above. Beware that if an IMEI (or `caller_id` or `callee_id` for that matter) has a phenomenally large call volume, that might be a call center and not a real person. (And we are only interested in real people in our project.) We first ask the question: How many distinct IMEI's are there in the dataset? We have made such a query before; let's try to do it again.

```{r distinct_imeis}
all.imeis <- mongo.distinct(mongo, namespace, "imei")
## This query results in an error because the returned list will be TOO BIG!
```

Note that this query wouldn't work if the result list is way too big to be returned. This is because MongoDB implements a cap of 16MB on the returned BSON document, see <http://docs.mongodb.org/manual/reference/limits/>. We will walk around this using the aggregation framework (and this kind of query will be very useful in the project as you'd have to retrieve large quantities of data over the network).

``` {r num_imeis}
pipe_1 <- mongo.bson.from.JSON(
  '{"$group":
    {"_id": "$imei", "count": {"$sum": 1}}
  }'
) 
pipe_2 <- mongo.bson.from.JSON(
   '{"$group":
    {"_id": 1, "count": {"$sum": 1}}
  }'
)
pipeline <- list(pipe_1, pipe_2)
## This query will take some time
(num.imeis <- mongo.aggregation(mongo, namespace, pipeline))
```

The result says that our collection has 2,331,947 unique IMEI's. Now can you query for the list of all IMEI's (or `caller_id`, `callee_id`) and retain those with *high enough* call volume only? These individuals will be the basis of our **social network**.

This is the end of the tutorial. You should repeat the same process to explore the other two collections: `taxi` and `income` in the `admin` database (by changing the `collection` variable correspondingly). Remember to change the corresponding field names as well. E-mail me should you encounter any problems. Have fun exploring!

**PS:** It is always a good practice to close and destroy the current `mongo` connection at the end of each session to release any network resources that might be attached to it.

```{r close_mongo, results='hide'}
mongo.disconnect(mongo)
mongo.destroy(mongo)
```

The following are good **online resources** to learn about `rmongodb` (and MongoDB in general):

* <http://cran.r-project.org/web/packages/rmongodb/vignettes/rmongodb_introduction.html>
* <https://gist.github.com/Btibert3/7751989#file-rmongodb-tutorial-md>
* <http://watson.nci.nih.gov/~sdavis/blog/rmongodb-using-R-with-mongo/>
* Aggregation framework: <https://www.mongosoup.de/blog-entry/rmongodb-using-the-MongoDB-Aggregations-Framework.html>
